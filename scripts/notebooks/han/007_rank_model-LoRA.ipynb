{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484c6fa5-fef0-4582-8ff2-8d47917f01e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f74571f-ff5d-480d-a622-5043962533f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1b002e-bf95-4aea-8dd2-ed8ae880b7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from optimizers import Adan, Lookahead, AGC\n",
    "from transformers import AutoTokenizer, AutoModel, CLIPTextModelWithProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f1c8ea-90b6-4969-a065-29b5f1500ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '../kcg-ml-image-pipeline/output/environmental/ranking_v1/'\n",
    "PMT_PATH = 'data/ranking_v1/prompt.json'\n",
    "# EMB_PATH = 'data/ranking_v1/bge_emb.npz'\n",
    "EMB_PATH = 'data/ranking_v1/clip_emb.npz'\n",
    "\n",
    "# MODEL_NAME = 'johngiorgi/declutr-base'\n",
    "MODEL_NAME = 'openai/clip-vit-large-patch14'\n",
    "# MODEL_NAME = 'BAAI/bge-base-en-v1.5'\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "MAX_LENGTH = 77\n",
    "\n",
    "LR = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba1c02-36b0-473f-bd6f-59b29dc1fa64",
   "metadata": {},
   "source": [
    "# load json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee6cd0d-a459-44de-a0f8-cde0f2c09020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_hashs = list()\n",
    "positive_prompts = list()\n",
    "negative_prompts = list()\n",
    "\n",
    "for file_hash, info in json.load(open(PMT_PATH)).items():\n",
    "    \n",
    "    file_hashs.append(file_hash)\n",
    "    positive_prompts.append(info['positive_prompt'])\n",
    "    negative_prompts.append(info['negative_prompt'])\n",
    "\n",
    "hash_to_index = {file_hash: i for i, file_hash in enumerate(file_hashs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5773745-3567-46e1-8d04-83c58ce19971",
   "metadata": {},
   "source": [
    "# load rank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a0d23bb-b4ec-4968-876a-b9b953924604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c64c9062c248d69a911cb0a2fd7c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = sorted(glob.glob(os.path.join(INPUT_DIR, 'ranking_data', '*.json')))\n",
    "\n",
    "rank_pairs = list()\n",
    "for path in tqdm(paths):\n",
    "    js = json.load(open(path))\n",
    "    if (js['image_1_metadata']['file_hash'] not in hash_to_index) or (js['image_2_metadata']['file_hash'] not in hash_to_index):\n",
    "        continue\n",
    "    rank_pairs.append((js['image_1_metadata']['file_hash'], js['image_2_metadata']['file_hash'], js['selected_image_index']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be10afb7-697a-469b-9d12-30b0f4e8447d",
   "metadata": {},
   "source": [
    "# check conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5be13a49-2a7b-4272-8fb7-e81f684d8c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ecdb763-ee57-4137-aad3-265d3af4744b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph = networkx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9233d2e4-774c-4ebb-8eb0-f17733a9b1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img_1, img_2, sel_id in rank_pairs:\n",
    "    if sel_id == 0:\n",
    "        graph.add_edge(img_2, img_1)\n",
    "    else:\n",
    "        graph.add_edge(img_1, img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fff3d971-c385-4f26-b660-796dafa31fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21305, 20786)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.nodes), len(graph.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65815de0-5895-46b1-a45b-42468270df42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    networkx.find_cycle(graph)\n",
    "    print('yes')\n",
    "except:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77e558-c0c4-48e8-8bd5-59ece4eeee9f",
   "metadata": {},
   "source": [
    "# check transitive relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1f3cf9c-bbc6-491e-b4bc-75f0ef2c31ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_1_hash</th>\n",
       "      <th>image_2_hash</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94bd853c68996549ff8218ef41614fd4a55d17007f7526...</td>\n",
       "      <td>12625f58a1d54b802da347103e48d441104bd5535d7d69...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94bd853c68996549ff8218ef41614fd4a55d17007f7526...</td>\n",
       "      <td>eb69aa30f3d6ec24c498f9be24f745f21e5ee1ec9562f6...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94bd853c68996549ff8218ef41614fd4a55d17007f7526...</td>\n",
       "      <td>fd411205f1face47e5c30440c52006446ff121daabc1f1...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3e865d7defa7498ff3bd1b42e5327924fb3cd518fee612...</td>\n",
       "      <td>bc6b3962f6cba734e99ca8bf0ee380a3d3793c2ef63490...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ae5c5cf41e086a6c57f870541f02af00d9fd83bcb12913...</td>\n",
       "      <td>711f811b470b7cf76efdec750c1378644ca47c615e640d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11468</th>\n",
       "      <td>6aaf0b10be77a1128456769d61aa8cd42c3adbfb82c749...</td>\n",
       "      <td>28815586ad87b725886e4d5bc8993a675eb8d97ded62b2...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11469</th>\n",
       "      <td>6aaf0b10be77a1128456769d61aa8cd42c3adbfb82c749...</td>\n",
       "      <td>6e1ec99e9086ca1a279692f755c58b9f257ee45f04609e...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11470</th>\n",
       "      <td>3afb53351878854cdf26926a00a35c260deb373587080a...</td>\n",
       "      <td>70292538d96042372703807148127983d55f2252d93898...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11471</th>\n",
       "      <td>deb5ce6e41f2983c075d9f3576d0ff1a66b5de0553ddc9...</td>\n",
       "      <td>c01cc3975673d628fc476de51261ebd925c8e401976a0b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11472</th>\n",
       "      <td>deb5ce6e41f2983c075d9f3576d0ff1a66b5de0553ddc9...</td>\n",
       "      <td>50463395c2ef27f8e19ea3803ef44c78b27173c0d2e1e5...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11473 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_1_hash  \\\n",
       "0      94bd853c68996549ff8218ef41614fd4a55d17007f7526...   \n",
       "1      94bd853c68996549ff8218ef41614fd4a55d17007f7526...   \n",
       "2      94bd853c68996549ff8218ef41614fd4a55d17007f7526...   \n",
       "3      3e865d7defa7498ff3bd1b42e5327924fb3cd518fee612...   \n",
       "4      ae5c5cf41e086a6c57f870541f02af00d9fd83bcb12913...   \n",
       "...                                                  ...   \n",
       "11468  6aaf0b10be77a1128456769d61aa8cd42c3adbfb82c749...   \n",
       "11469  6aaf0b10be77a1128456769d61aa8cd42c3adbfb82c749...   \n",
       "11470  3afb53351878854cdf26926a00a35c260deb373587080a...   \n",
       "11471  deb5ce6e41f2983c075d9f3576d0ff1a66b5de0553ddc9...   \n",
       "11472  deb5ce6e41f2983c075d9f3576d0ff1a66b5de0553ddc9...   \n",
       "\n",
       "                                            image_2_hash  dist  \n",
       "0      12625f58a1d54b802da347103e48d441104bd5535d7d69...     2  \n",
       "1      eb69aa30f3d6ec24c498f9be24f745f21e5ee1ec9562f6...     2  \n",
       "2      fd411205f1face47e5c30440c52006446ff121daabc1f1...     3  \n",
       "3      bc6b3962f6cba734e99ca8bf0ee380a3d3793c2ef63490...     2  \n",
       "4      711f811b470b7cf76efdec750c1378644ca47c615e640d...     2  \n",
       "...                                                  ...   ...  \n",
       "11468  28815586ad87b725886e4d5bc8993a675eb8d97ded62b2...     3  \n",
       "11469  6e1ec99e9086ca1a279692f755c58b9f257ee45f04609e...     4  \n",
       "11470  70292538d96042372703807148127983d55f2252d93898...     2  \n",
       "11471  c01cc3975673d628fc476de51261ebd925c8e401976a0b...     2  \n",
       "11472  50463395c2ef27f8e19ea3803ef44c78b27173c0d2e1e5...     3  \n",
       "\n",
       "[11473 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_pairs = list()\n",
    "\n",
    "for image_1_hash, d in networkx.all_pairs_shortest_path_length(graph):\n",
    "    \n",
    "    for image_2_hash, dist in d.items():\n",
    "        \n",
    "        if dist <= 1:\n",
    "            continue\n",
    "        \n",
    "        trans_pairs.append((image_1_hash, image_2_hash, dist))\n",
    "        \n",
    "trans_pairs = pd.DataFrame(trans_pairs, columns=['image_1_hash', 'image_2_hash', 'dist'])\n",
    "trans_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa64249b-1f2e-4b49-8276-b212a025865a",
   "metadata": {},
   "source": [
    "# build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb9e078-75f0-4776-a3aa-b71b0c2afd0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dab3128-25db-468a-822c-a3ee1804926b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_encodings = tokenizer(\n",
    "    positive_prompts,\n",
    "    truncation=True, max_length=MAX_LENGTH, return_length=True,\n",
    "    return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\"\n",
    ")[\"input_ids\"]\n",
    "\n",
    "negative_encodings = tokenizer(\n",
    "    negative_prompts,\n",
    "    truncation=True, max_length=MAX_LENGTH, return_length=True,\n",
    "    return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\"\n",
    ")[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acacb29d-b8eb-48db-ae01-0293e4010e07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_1_hash</th>\n",
       "      <th>image_2_hash</th>\n",
       "      <th>selected_image_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42ee13e91ac7b709f896077d98edbcb38b931a13306446...</td>\n",
       "      <td>94bd853c68996549ff8218ef41614fd4a55d17007f7526...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61ccff95c06b49b9f1bc4abe15af2598bc6e93b6ed9a68...</td>\n",
       "      <td>3d85873e61357ffb38928e22987881c893974b3c7b7720...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93d5b322d9c6b8d3580194edbea662fe28c180dcca9c2b...</td>\n",
       "      <td>4fda19572c7e06ce84004133a05881fb234baf6549f5c2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6bfc50f135f87f180f8a9473bd781e634aebc5e319cc3f...</td>\n",
       "      <td>3e865d7defa7498ff3bd1b42e5327924fb3cd518fee612...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38ce0e30d209fb4557266e539771b2e98aa5628f352acf...</td>\n",
       "      <td>ae5c5cf41e086a6c57f870541f02af00d9fd83bcb12913...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20784</th>\n",
       "      <td>9d7aff5a30da7b273d16c07a9a6f9daf14ae8ed61d7bd7...</td>\n",
       "      <td>7266b827572fc60cf8bccf5b6254a64dac36594fe06e7d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20785</th>\n",
       "      <td>deb5ce6e41f2983c075d9f3576d0ff1a66b5de0553ddc9...</td>\n",
       "      <td>d2e88eb8cad25a573bc3a1c694cdbc943de2066c99930a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20786</th>\n",
       "      <td>b9d3ee83e298901067830713e5e43eda8b4c10e96d9a6b...</td>\n",
       "      <td>b022e36aef205e4d38a1251d71e2786f8568a4e2d9b060...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20787</th>\n",
       "      <td>96ad2f1eef6e9ad0e82f19190cd2df3422af942cad918f...</td>\n",
       "      <td>564018a5784243393f81ac52c02aa71227ea741a363cdb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20788</th>\n",
       "      <td>6b015432a23d834a5cb72b84ab8c89498acfde87e22272...</td>\n",
       "      <td>16d8f3e2b514cf7fc6b2733c3f58741486623c819c38ed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20789 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_1_hash  \\\n",
       "0      42ee13e91ac7b709f896077d98edbcb38b931a13306446...   \n",
       "1      61ccff95c06b49b9f1bc4abe15af2598bc6e93b6ed9a68...   \n",
       "2      93d5b322d9c6b8d3580194edbea662fe28c180dcca9c2b...   \n",
       "3      6bfc50f135f87f180f8a9473bd781e634aebc5e319cc3f...   \n",
       "4      38ce0e30d209fb4557266e539771b2e98aa5628f352acf...   \n",
       "...                                                  ...   \n",
       "20784  9d7aff5a30da7b273d16c07a9a6f9daf14ae8ed61d7bd7...   \n",
       "20785  deb5ce6e41f2983c075d9f3576d0ff1a66b5de0553ddc9...   \n",
       "20786  b9d3ee83e298901067830713e5e43eda8b4c10e96d9a6b...   \n",
       "20787  96ad2f1eef6e9ad0e82f19190cd2df3422af942cad918f...   \n",
       "20788  6b015432a23d834a5cb72b84ab8c89498acfde87e22272...   \n",
       "\n",
       "                                            image_2_hash  selected_image_index  \n",
       "0      94bd853c68996549ff8218ef41614fd4a55d17007f7526...                     0  \n",
       "1      3d85873e61357ffb38928e22987881c893974b3c7b7720...                     0  \n",
       "2      4fda19572c7e06ce84004133a05881fb234baf6549f5c2...                     1  \n",
       "3      3e865d7defa7498ff3bd1b42e5327924fb3cd518fee612...                     0  \n",
       "4      ae5c5cf41e086a6c57f870541f02af00d9fd83bcb12913...                     0  \n",
       "...                                                  ...                   ...  \n",
       "20784  7266b827572fc60cf8bccf5b6254a64dac36594fe06e7d...                     0  \n",
       "20785  d2e88eb8cad25a573bc3a1c694cdbc943de2066c99930a...                     1  \n",
       "20786  b022e36aef205e4d38a1251d71e2786f8568a4e2d9b060...                     1  \n",
       "20787  564018a5784243393f81ac52c02aa71227ea741a363cdb...                     0  \n",
       "20788  16d8f3e2b514cf7fc6b2733c3f58741486623c819c38ed...                     1  \n",
       "\n",
       "[20789 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_pairs = pd.DataFrame(rank_pairs, columns=['image_1_hash', 'image_2_hash', 'selected_image_index'])\n",
    "\n",
    "rank_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec4ca95e-0435-4e3e-9187-7375d6e43a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordered_pairs = [((image_1_hash, image_2_hash) if selected_image_index == 0 else (image_2_hash, image_1_hash)) for image_1_hash, image_2_hash, selected_image_index in rank_pairs.itertuples(index=False, name=None)]\n",
    "ordered_pairs = pd.DataFrame(ordered_pairs, columns=['image_1_hash', 'image_2_hash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0bf066c-a6ea-4345-8b14-f828a34d83af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pairs, val_pairs = train_test_split(ordered_pairs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bf6ce97-aeba-482f-8f1b-7591a8914427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21305"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((set(rank_pairs['image_1_hash']) | set(rank_pairs['image_2_hash'])) | set(file_hashs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4eb257-225c-4222-9070-21b5512d5cd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## build feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df0132fe-c342-4b1a-9eb4-94af3f2c3d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_feature(index_1, index_2, use_positive=True, use_negative=False):\n",
    "    \n",
    "    results = list()\n",
    "    if use_positive:\n",
    "        results.append(torch.stack([positive_encodings[index_1], positive_encodings[index_2]], dim=-1))\n",
    "    if use_negative:\n",
    "        results.append(torch.stack([negative_encodings[index_1], negative_encodings[index_2]], dim=-1))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4224f943-eeb1-47e3-97ab-1abc6671d8b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16631, 77, 2]), torch.Size([4158, 77, 2]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = list()\n",
    "for image_1_hash, image_2_hash in train_pairs.itertuples(index=False, name=None):\n",
    "    index_1, index_2 = hash_to_index[image_1_hash], hash_to_index[image_2_hash]\n",
    "    train_data.append(build_feature(index_1, index_2, use_positive=True, use_negative=False)[0])\n",
    "train_data = torch.stack(train_data, axis=0)\n",
    "\n",
    "val_data = list()\n",
    "for image_1_hash, image_2_hash in val_pairs.itertuples(index=False, name=None):\n",
    "    index_1, index_2 = hash_to_index[image_1_hash], hash_to_index[image_2_hash]\n",
    "    val_data.append(build_feature(index_1, index_2, use_positive=True, use_negative=False)[0])\n",
    "val_data = torch.stack(val_data, axis=0)\n",
    "\n",
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48fb3198-322d-4019-99a5-9334b03d4486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ext_data = list()\n",
    "# for image_1_hash, image_2_hash in trans_pairs[['image_1_hash', 'image_2_hash']].itertuples(index=False, name=None):\n",
    "#     index_1, index_2 = hash_to_index[image_1_hash], hash_to_index[image_2_hash]\n",
    "#     ext_data.append(build_feature(index_1, index_2, use_positive=True, use_negative=False, use_mask=True)[0])\n",
    "# ext_data = np.stack(ext_data, axis=0)\n",
    "# ext_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790b38f-8a6a-4606-9cc4-0ef9719920a5",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a471b795-fe8d-44e2-8ee2-dd1eb2ce6e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if BATCH_SIZE > 0:\n",
    "    train_dataset = train_data.pin_memory()\n",
    "    val_dataset = val_data.pin_memory()\n",
    "else:\n",
    "    train_dataset = train_data.cuda()\n",
    "    val_dataset = val_data.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac29f2c-000d-4c00-b2b8-61ad697c34e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CLIPTextModelWithProjection.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    # subfolder='text_encoder',\n",
    "    projection_dim=1, \n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a40015-a99e-46c3-8fe3-f3b4579ea7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38033266-b9a0-47b0-9e76-9ec3fede8f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters = list(model.parameters())\n",
    "parameters = list(model.text_model.final_layer_norm.parameters()) + list(model.text_model.parameters())\n",
    "\n",
    "optimizer = AdamW(parameters, lr=LR, weight_decay=1e-3)\n",
    "# optimizer = Adan(parameters, lr=LR, weight_decay=1e-3)\n",
    "# optimizer = Lookahead(optimizer)\n",
    "# optimizer = AGC(optimizer)\n",
    "warmup = torch.optim.lr_scheduler.LambdaLR(optimizer, [lambda step: step / 100. if step < 100 else 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecfc7a-ef62-4c02-a8e8-3e6dbfdb4483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model.cuda())\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718ee1d-6859-43f8-87bf-ff934d0ea440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "bces, accs = list(), list()\n",
    "\n",
    "for epoch in tqdm(range(2)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    if BATCH_SIZE > 0:\n",
    "        label = torch.zeros((BATCH_SIZE,), device='cuda').long()\n",
    "        loader = range(BATCH_SIZE, train_dataset.shape[0], BATCH_SIZE)\n",
    "    else:\n",
    "        label = torch.zeros((train_dataset.shape[0],), device='cuda').long()\n",
    "        loader = [train_dataset.shape[0]]\n",
    "    \n",
    "    for i in loader:\n",
    "    \n",
    "        if BATCH_SIZE > 0:\n",
    "            x = train_dataset[i-BATCH_SIZE:i]\n",
    "        else:\n",
    "            x = train_dataset\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "\n",
    "            y0 = model(x[..., 0].cuda()).text_embeds\n",
    "            y1 = model(x[..., 1].cuda()).text_embeds\n",
    "            \n",
    "            y = torch.concat([y0, y1], dim=-1)\n",
    "\n",
    "        # backward\n",
    "\n",
    "        bce = torch.nn.functional.cross_entropy(y, label)\n",
    "\n",
    "        acc = (y.argmax(dim=-1) == 0).float().mean()\n",
    "\n",
    "        loss = bce\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        warmup.step()\n",
    "\n",
    "        bces.append(bce.detach().cpu().numpy())\n",
    "        accs.append(acc.detach().cpu().numpy())\n",
    "        \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        val_bces, val_accs = list(), list()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            with torch.cuda.amp.autocast(True):\n",
    "\n",
    "                if BATCH_SIZE > 0:\n",
    "                    loader = range(BATCH_SIZE, val_dataset.shape[0], BATCH_SIZE)\n",
    "                else:\n",
    "                    loader = [val_dataset.shape[0]]\n",
    "\n",
    "                for i in loader:\n",
    "\n",
    "                    if BATCH_SIZE > 0:\n",
    "                        x = val_dataset[i:i+BATCH_SIZE]\n",
    "                    else:\n",
    "                        x = val_dataset\n",
    "\n",
    "                    y0 = model(x[..., 0].cuda()).text_embeds\n",
    "                    y1 = model(x[..., 1].cuda()).text_embeds\n",
    "\n",
    "                    y = torch.concat([y0, y1], dim=-1)\n",
    "\n",
    "                    label = torch.zeros((y.shape[0],), device='cuda').long()\n",
    "\n",
    "                    bce = torch.nn.functional.cross_entropy(y, label)\n",
    "\n",
    "                    acc = (y.argmax(dim=-1) == 0).float().mean()\n",
    "\n",
    "                    val_bces.append(bce.detach().cpu().numpy())\n",
    "                    val_accs.append(acc.detach().cpu().numpy())\n",
    "\n",
    "        print(f'{epoch+1}\\t{np.mean(bces):.4f} {np.mean(accs):.4f} {np.mean(val_bces):.4f} {np.mean(val_accs):.4f}')\n",
    "    \n",
    "        bces, accs = list(), list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d15c3e-8772-45fd-9c2a-b77a8fd6be6f",
   "metadata": {},
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c064c-74e6-4786-a205-36f9fb5112e5",
   "metadata": {},
   "source": [
    "## val set distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c8368-d0fb-487a-b6fc-1b666e099c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "y0s, y1s = list(), list()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    with torch.cuda.amp.autocast(True):\n",
    "\n",
    "        if BATCH_SIZE > 0:\n",
    "            loader = range(BATCH_SIZE, val_dataset.shape[0], BATCH_SIZE)\n",
    "        else:\n",
    "            loader = [val_dataset.shape[0]]\n",
    "\n",
    "        for i in loader:\n",
    "\n",
    "            if BATCH_SIZE > 0:\n",
    "                x = val_dataset[i:i+BATCH_SIZE]\n",
    "            else:\n",
    "                x = val_dataset\n",
    "\n",
    "            y0 = model(x[..., 0].cuda()).text_embeds\n",
    "            y1 = model(x[..., 1].cuda()).text_embeds\n",
    "\n",
    "            y0s.append(y0.detach().cpu().numpy())\n",
    "            y1s.append(y1.detach().cpu().numpy())\n",
    "            \n",
    "y0 = np.concatenate(y0s, axis=0)\n",
    "y1 = np.concatenate(y1s, axis=0)\n",
    "\n",
    "val_delta = (y0 - y1)[..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32baede3-fbee-4807-ac10-763fc701e664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = pyplot.hist(val_delta, bins=100, density=True)\n",
    "pyplot.title('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a9d10-e909-47c0-9258-d6d0e6ccaec9",
   "metadata": {},
   "source": [
    "## score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5b0fd-5c57-427c-8b31-c0ac836f1204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "scores = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast(True):\n",
    "        \n",
    "        if BATCH_SIZE > 0:\n",
    "            loader = range(BATCH_SIZE, positive_encodings.shape[0], BATCH_SIZE)\n",
    "        else:\n",
    "            loader = [positive_encodings.shape[0]]\n",
    "\n",
    "        for i in loader:\n",
    "\n",
    "            if BATCH_SIZE > 0:\n",
    "                x = positive_encodings[i:i+BATCH_SIZE]\n",
    "            else:\n",
    "                x = positive_encodings\n",
    "\n",
    "            score = model(torch.tensor(x).cuda()).text_embeds\n",
    "            scores.append(score[..., 0].detach().cpu().numpy())\n",
    "        \n",
    "score = np.concatenate(scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5f039-1da9-4ba2-a782-80d628e6c94a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = pyplot.hist(score, bins=100, density=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d26b80-b0d2-42f9-9789-a0a58127d7bd",
   "metadata": {},
   "source": [
    "## prepare for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a4dd7-19b3-4fad-9b28-522a8d759dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "js = json.load(open(PMT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ecc75-0ca9-4e7a-a5b4-c0297d3fcaa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d71387-2b74-431d-8fd7-365dd9c413be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_details(prompt_sequences: list, embedding_sequences, topk=3):\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        prompt_sequences,\n",
    "        truncation=True, max_length=77, return_length=True,\n",
    "        return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids']\n",
    "    \n",
    "    x = torch.tensor(embedding_sequences).half()\n",
    "    x = x.view(-1, *x.shape[-2:]).permute(0, 2, 1)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "\n",
    "            attn, scores, score = model(x.cuda(), return_all=True)\n",
    "\n",
    "            attn = attn.detach().cpu().numpy()\n",
    "            scores = scores.detach().cpu().numpy()\n",
    "            score = score.detach().cpu().numpy()\n",
    "            \n",
    "    results = list()\n",
    "\n",
    "    for t_is, t_as, t_ss, s in zip(input_ids, attn, scores, score):\n",
    "\n",
    "        tokens = tokenizer.convert_ids_to_tokens(t_is)\n",
    "        \n",
    "        tags = list()\n",
    "        last = ([], [], [])\n",
    "        for token, t_a, t_s in zip(tokens, t_as[0], t_ss[0]):\n",
    "\n",
    "            token = token.replace('</w>', '')\n",
    "\n",
    "            last_tokens, last_as, last_ss = last\n",
    "\n",
    "            if token[0] in ['<', '['] and token[-1] in ['>', ']']:\n",
    "                if len(last_tokens) > 0:\n",
    "                    tags.append((' '.join(last_tokens), sum(last_as), sum(i*j for i, j in zip(last_as, last_ss)) / sum(last_as)))\n",
    "                tags.append((token, t_a, t_s))\n",
    "                last = ([], [], [])\n",
    "            else:\n",
    "                last_tokens.append(token)\n",
    "                last_as.append(t_a)\n",
    "                last_ss.append(t_s)\n",
    "\n",
    "                if ',' in token:\n",
    "                    tags.append((' '.join(last_tokens), sum(last_as), sum(i*j for i, j in zip(last_as, last_ss)) / sum(last_as)))\n",
    "                    last = ([], [], [])\n",
    "\n",
    "        last_tokens, last_as, last_ss = last\n",
    "        if len(last_tokens) > 0:\n",
    "            tags.append((' '.join(last_tokens), sum(last_as), sum(i*j for i, j in zip(last_as, last_ss)) / sum(last_as)))\n",
    "            \n",
    "        t_texts, t_attns, t_scores = zip(*tags)\n",
    "        \n",
    "        topk_ids = np.argsort(t_attns)[::-1][:topk]\n",
    "\n",
    "        results.append([s[0]] + sum([[t_texts[i], t_attns[i], t_scores[i]] for i in topk_ids], start=[]))     \n",
    "\n",
    "#         topk_ids = np.argsort(as[0])[::-1][:topk]\n",
    "\n",
    "#         results.append((s[0],) + sum(zip([tokens[i].replace('</w>', '') for i in topk_ids], as[0, topk_ids], ss[0, topk_ids]), start=()))     \n",
    "    \n",
    "    results = pd.DataFrame(results, columns=['score'] + sum([[f'{i+1}-token', f'{i+1}-weight', f'{i+1}-score'] for i in range(topk)], start=[]))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c6417-dbb1-444f-b7df-f126133a6da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_samples(indices, n_select):\n",
    "    \n",
    "    selected = np.random.choice(indices, n_select, False)\n",
    "    \n",
    "    file_paths = [js[file_hashs[i]]['file_path'] for i in selected]\n",
    "    file_paths = [i.replace('_embedding.msgpack', '.jpg') for i in file_paths]\n",
    "    \n",
    "    images = np.stack([np.array(Image.open(os.path.join('../kcg-ml-image-pipeline/output/dataset/', i))) for i in file_paths])\n",
    "    images = images.reshape(-1, int(n_select ** 0.5), *images.shape[-3:])\n",
    "    images = np.concatenate(np.concatenate(images, axis=-3), axis=-2)\n",
    "    \n",
    "    images = Image.fromarray(images).resize((512, 512))\n",
    "    \n",
    "    return selected, images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa64af-8bc8-49b6-8dd7-24e9a30179ea",
   "metadata": {},
   "source": [
    "## show top score samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa0365-1b06-4cb8-bd93-40dadc25e412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.quantile(score, q=0.95)\n",
    "selected, images = select_samples(np.arange(score.shape[0])[score > threshold], n_select=9)\n",
    "\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ab560-ded4-4c98-832e-e54388245430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac7d9a5-248e-40e2-9c70-624f38ecc53c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_details(\n",
    "    [js[i]['positive_prompt'] for i in file_hashs[selected]], \n",
    "    positive_last_hidden_states_with_mask[selected]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f4098-70ab-406e-a622-1ac2ea375702",
   "metadata": {},
   "source": [
    "## show lowest score samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b34e14-b204-4fda-931b-13731af526bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.quantile(score, q=0.05)\n",
    "selected, images = select_samples(np.arange(score.shape[0])[score < threshold], n_select=9)\n",
    "\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df23d2-5589-46fa-be11-04dcdcd31402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119869b-ab3e-4bff-8ada-d9603b9f9a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_details(\n",
    "    [js[i]['positive_prompt'] for i in file_hashs[selected]], \n",
    "    positive_last_hidden_states_with_mask[selected]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d2b508-a0e9-4d7c-9319-276d204c9403",
   "metadata": {},
   "source": [
    "## show lowest delta samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a79c2d-7c0f-48a0-b348-032e657f0121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_select = 6\n",
    "\n",
    "# threshold = np.quantile(val_delta, q=0.05)\n",
    "# indices = val_pairs.index[np.arange(val_delta.shape[0])[val_delta < threshold]]\n",
    "# selected = np.random.choice(indices, n_select, False)\n",
    "\n",
    "selected = val_pairs.index[np.argsort(val_delta)[:n_select]]\n",
    "\n",
    "indices_1 = [hash_to_index[i] for i in val_pairs.loc[selected, 'image_1_hash']]\n",
    "indices_2 = [hash_to_index[i] for i in val_pairs.loc[selected, 'image_2_hash']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73d072-bf67-4bbf-bdd2-cb471de0f34d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_paths = [js[file_hashs[i]]['file_path'] for i in indices_1]\n",
    "file_paths = [i.replace('_embedding.msgpack', '.jpg') for i in file_paths]\n",
    "\n",
    "images = np.stack([np.array(Image.open(os.path.join('../kcg-ml-image-pipeline/output/dataset/', i))) for i in file_paths])\n",
    "images_1 = np.concatenate(images, axis=-2)\n",
    "\n",
    "file_paths = [js[file_hashs[i]]['file_path'] for i in indices_2]\n",
    "file_paths = [i.replace('_embedding.msgpack', '.jpg') for i in file_paths]\n",
    "\n",
    "images = np.stack([np.array(Image.open(os.path.join('../kcg-ml-image-pipeline/output/dataset/', i))) for i in file_paths])\n",
    "images_2 = np.concatenate(images, axis=-2)\n",
    "\n",
    "images = np.concatenate([images_1, images_2], axis=-3)\n",
    "\n",
    "images = Image.fromarray(images).resize((512 * n_select // 2, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c234c-b88e-4513-8c79-148c2cc0eb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2f0bc-3d6d-4e6c-b1c0-69fe6e72f6c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_details(\n",
    "    [js[i]['positive_prompt'] for i in file_hashs[indices_1]], \n",
    "    positive_last_hidden_states_with_mask[indices_1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7d35f-11b9-401d-82ef-146ac24ba216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_details(\n",
    "    [js[i]['positive_prompt'] for i in file_hashs[indices_2]], \n",
    "    positive_last_hidden_states_with_mask[indices_2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe42441f-5298-4770-8a8f-f81db5e523d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk",
   "language": "python",
   "name": "kk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
